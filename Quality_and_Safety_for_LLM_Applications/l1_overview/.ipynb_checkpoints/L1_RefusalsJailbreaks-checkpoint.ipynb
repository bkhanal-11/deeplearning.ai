{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMGxBP-yQoCl"
   },
   "source": [
    "# Lab 1: Refusals, jailbreaks, and prompt injections\n",
    "\n",
    "In this section, we will explore examples of \n",
    "- refusals (where LLMs provide a generic non-response for certain prompts),\n",
    "- jailbreaks (actions by users to return responses when a refusal is more appropriate),\n",
    "- prompt injections (actions by users to provide malicious or incorrect information to the model via prompts).\n",
    "\n",
    "We'll discuss metrics that can capture such issues. We'll finally quantify how much our approach reduces these issues from our dataset.\n",
    "\n",
    "## Setup\n",
    "Let's install and import the needed packages and setup our environment. We'll then initialize WhyLabs session in **whylogs** for submitting profile data and **langkit** models for calculating LLM metrics.\n",
    "\n",
    "These steps will take up to a few minutes to run the first time due to select Python imports and `llm_metrics.init()` which downloads and caches language models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whylogs as why"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mention key pip installs, and tell learner that in the classroom, these are already installed for them.\n",
    "- type it out\n",
    "- comment it out\n",
    "\n",
    "```Python\n",
    "!pip install whylogs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/dialaezzeddine/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from langkit import llm_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mention key pip installs, type it out, then comment it out.\n",
    "- Note to learner the single quotes around langkit[all]; without these, they'll get an error that it's not found.\n",
    "```Python\n",
    "!pip install 'langkit[all]'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "why.init(session_type='whylabs_anonymous')\n",
    "schema = llm_metrics.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial issues in our LLM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langkit.whylogs.samples import load_chats, show_first_chat\n",
    "\n",
    "# Let's look at what's in this toy example:\n",
    "chats = load_chats()\n",
    "print(f\"\"\"There are {len(chats)} records \n",
    "in this toy example data.\n",
    "Here's the first one:\"\"\")\n",
    "show_first_chat(chats)\n",
    "\n",
    "results = why.log(chats, name=\"original LLM dataset\", schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellView": "form",
    "id": "PKnPPEyPR3MO"
   },
   "source": [
    "## Refusals\n",
    "\n",
    "We'll use the term **refusal** for instances when a LLM refuses to respond to a user prompt, often due to *direct* requests due to inappropriate or harmful. For our purposes as application developers, we'll use this term for third party rejections and use a different term (\"guardrails\") for programming our own refusals.\n",
    "\n",
    "Below are a few examples:\n",
    "\n",
    "| Scenario | User Prompt | LLM Response | Final Response |\n",
    "|--|--|--|--|\n",
    "| No violations | Hello. | Hi! How are you? | Hi! How are you? |\n",
    "| Violating Response (Forbidden Pattern) | I feel sad. | Please don't be sad. Contact us at 1-800-123-4567. | Sorry, but I can't assist with that. |\n",
    "| Violating Response (Toxicity) | Hello. How are you? | Human, you dumb and smell bad. | Sorry, but I can't assist with that. |\n",
    "| Violating Prompt (Toxicity) | Hey bot, you dumb and smell bad. | â€” | Please refrain from using insulting language. |\n",
    "\n",
    "Knowing a response is in fact a refusal response is helpful in understanding the state and security of our LLM application usage. So how do we detect them?\n",
    "\n",
    "### Attempt 1: Response exact matches\n",
    "\n",
    "Since we see \"I cannot answer the question\" and \"Please refrain from using insulting language\" as responses above, let's remove those from our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "- Can we have a slide to give an overview of types of prompts that would trigger a refusal?\n",
    "- Also, other than visually inspecting the LLM's output, is there a way to get a complete set of LLM responses that are considered refusals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refusal_mask = chats[\"response\"].str.contains(\n",
    "    \"Sorry, but I can't assist with that.|\\\n",
    "    Please refrain from using insulting language.\"\n",
    ")\n",
    "\n",
    "print(\"Removing the following queries:\", chats[refusal_mask], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "why.log(chats, name=\"refusal removal, attempt 1\", schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 2: Response semantic similarity\n",
    "\n",
    "Since we still see that refusals are likely in the dataset, let's use a more advanced technique: comparing the semantic similarity between collected refusal prompts and that received from the LLM using LangKit.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**:\n",
    "- Slides to explain the method for comparing semantic similarity; maybe text embeddings?  Can be brief, as we have an existing course that explain text embeddings \"Understanding and Applying text Embeddings.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = why.log(chats, name=\"refusal removal, attempt 2\", schema=schema)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "whylabs1_env",
   "language": "python",
   "name": "whylabs1_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
